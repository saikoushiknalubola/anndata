{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb8ea1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:34.050469Z",
     "iopub.status.busy": "2025-05-22T15:08:34.050210Z",
     "iopub.status.idle": "2025-05-22T15:08:54.915536Z",
     "shell.execute_reply": "2025-05-22T15:08:54.914646Z"
    },
    "papermill": {
     "duration": 20.871318,
     "end_time": "2025-05-22T15:08:54.917354",
     "exception": false,
     "start_time": "2025-05-22T15:08:34.046036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Soil Classification\n",
    "# High-accuracy model with TTA, Cross-validation, and Ensembling\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48623d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:54.924728Z",
     "iopub.status.busy": "2025-05-22T15:08:54.924344Z",
     "iopub.status.idle": "2025-05-22T15:08:54.938853Z",
     "shell.execute_reply": "2025-05-22T15:08:54.938274Z"
    },
    "papermill": {
     "duration": 0.01938,
     "end_time": "2025-05-22T15:08:54.940022",
     "exception": false,
     "start_time": "2025-05-22T15:08:54.920642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5eb06f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:54.947149Z",
     "iopub.status.busy": "2025-05-22T15:08:54.946431Z",
     "iopub.status.idle": "2025-05-22T15:08:54.950311Z",
     "shell.execute_reply": "2025-05-22T15:08:54.949713Z"
    },
    "papermill": {
     "duration": 0.008265,
     "end_time": "2025-05-22T15:08:54.951344",
     "exception": false,
     "start_time": "2025-05-22T15:08:54.943079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "TRAIN_DIR = \"/kaggle/input/soil-classification/soil_classification-2025/train\"\n",
    "TEST_DIR = \"/kaggle/input/soil-classification/soil_classification-2025/test\"\n",
    "LABELS_PATH = \"/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv\"\n",
    "TEST_IDS_PATH = \"/kaggle/input/soil-classification/soil_classification-2025/test_ids.csv\"\n",
    "SUBMISSION_PATH = \"/kaggle/working/submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b06002ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:54.957260Z",
     "iopub.status.busy": "2025-05-22T15:08:54.956993Z",
     "iopub.status.idle": "2025-05-22T15:08:55.034773Z",
     "shell.execute_reply": "2025-05-22T15:08:55.033706Z"
    },
    "papermill": {
     "duration": 0.08237,
     "end_time": "2025-05-22T15:08:55.036302",
     "exception": false,
     "start_time": "2025-05-22T15:08:54.953932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load labels\n",
    "labels_df = pd.read_csv(LABELS_PATH)\n",
    "class_names = labels_df[\"soil_type\"].unique().tolist()\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
    "labels_df[\"label\"] = labels_df[\"soil_type\"].map(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7350ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:55.042699Z",
     "iopub.status.busy": "2025-05-22T15:08:55.042162Z",
     "iopub.status.idle": "2025-05-22T15:08:55.047827Z",
     "shell.execute_reply": "2025-05-22T15:08:55.047096Z"
    },
    "papermill": {
     "duration": 0.010029,
     "end_time": "2025-05-22T15:08:55.049039",
     "exception": false,
     "start_time": "2025-05-22T15:08:55.039010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class SoilDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx][\"image_id\"]\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.df.iloc[idx][\"label\"]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcceeb9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:55.055216Z",
     "iopub.status.busy": "2025-05-22T15:08:55.054858Z",
     "iopub.status.idle": "2025-05-22T15:08:55.060182Z",
     "shell.execute_reply": "2025-05-22T15:08:55.059610Z"
    },
    "papermill": {
     "duration": 0.009711,
     "end_time": "2025-05-22T15:08:55.061370",
     "exception": false,
     "start_time": "2025-05-22T15:08:55.051659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "image_size = 224\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69fb8937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:55.067197Z",
     "iopub.status.busy": "2025-05-22T15:08:55.066953Z",
     "iopub.status.idle": "2025-05-22T15:08:55.070850Z",
     "shell.execute_reply": "2025-05-22T15:08:55.070257Z"
    },
    "papermill": {
     "duration": 0.008079,
     "end_time": "2025-05-22T15:08:55.072090",
     "exception": false,
     "start_time": "2025-05-22T15:08:55.064011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "def create_model():\n",
    "    model = models.efficientnet_b0(pretrained=True)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7cb330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:55.078366Z",
     "iopub.status.busy": "2025-05-22T15:08:55.077786Z",
     "iopub.status.idle": "2025-05-22T15:08:55.082892Z",
     "shell.execute_reply": "2025-05-22T15:08:55.081929Z"
    },
    "papermill": {
     "duration": 0.009695,
     "end_time": "2025-05-22T15:08:55.084364",
     "exception": false,
     "start_time": "2025-05-22T15:08:55.074669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ca25d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:55.090309Z",
     "iopub.status.busy": "2025-05-22T15:08:55.089803Z",
     "iopub.status.idle": "2025-05-22T15:08:55.095325Z",
     "shell.execute_reply": "2025-05-22T15:08:55.094540Z"
    },
    "papermill": {
     "duration": 0.009723,
     "end_time": "2025-05-22T15:08:55.096592",
     "exception": false,
     "start_time": "2025-05-22T15:08:55.086869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    per_class_f1 = [f1_score(np.array(y_true)==i, np.array(y_pred)==i) for i in range(len(class_names))]\n",
    "    return per_class_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e80e00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:08:55.102405Z",
     "iopub.status.busy": "2025-05-22T15:08:55.102198Z",
     "iopub.status.idle": "2025-05-22T15:16:28.212638Z",
     "shell.execute_reply": "2025-05-22T15:16:28.211575Z"
    },
    "papermill": {
     "duration": 453.188973,
     "end_time": "2025-05-22T15:16:28.288087",
     "exception": false,
     "start_time": "2025-05-22T15:08:55.099114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:00<00:00, 110MB/s] \n",
      "100%|██████████| 31/31 [00:11<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5801, Per-class F1: [0.9423 0.8293 0.955  0.9213], Min F1: 0.8293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.1890, Per-class F1: [0.9577 0.8642 0.9905 0.9011], Min F1: 0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.1057, Per-class F1: [0.9671 0.975  0.9811 0.967 ], Min F1: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0973, Per-class F1: [0.9484 0.9231 0.9725 0.9778], Min F1: 0.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0787, Per-class F1: [0.9623 0.95   0.9725 0.9663], Min F1: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0672, Per-class F1: [0.9577 0.962  0.9725 0.9663], Min F1: 0.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0474, Per-class F1: [0.9674 0.95   1.     0.9663], Min F1: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0534, Per-class F1: [0.9767 0.975  1.     0.9663], Min F1: 0.9663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0394, Per-class F1: [0.968  0.961  1.     0.9545], Min F1: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0391, Per-class F1: [0.977  0.9474 1.     0.989 ], Min F1: 0.9474\n",
      "\n",
      "===== Fold 2 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6132, Per-class F1: [0.9372 0.8434 0.9905 0.9684], Min F1: 0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.1644, Per-class F1: [0.9615 0.8537 0.9804 0.9592], Min F1: 0.8537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0911, Per-class F1: [0.9671 0.9114 1.     1.    ], Min F1: 0.9114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0705, Per-class F1: [0.972  0.9231 1.     1.    ], Min F1: 0.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0725, Per-class F1: [0.9811 0.9211 0.9903 0.9495], Min F1: 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0584, Per-class F1: [0.9906 0.975  1.     0.9787], Min F1: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0763, Per-class F1: [0.9758 0.9524 0.9804 0.9691], Min F1: 0.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0540, Per-class F1: [0.9808 0.9383 1.     0.9691], Min F1: 0.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0248, Per-class F1: [0.9905 0.9877 1.     0.9895], Min F1: 0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.32it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0190, Per-class F1: [0.9906 0.9487 1.     0.9583], Min F1: 0.9487\n",
      "\n",
      "===== Fold 3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6338, Per-class F1: [0.9254 0.8333 0.9815 0.9684], Min F1: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.1579, Per-class F1: [0.9569 0.8889 1.     1.    ], Min F1: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.1071, Per-class F1: [0.9565 0.878  0.9811 0.9892], Min F1: 0.8780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0856, Per-class F1: [0.9561 0.9048 0.9709 0.9583], Min F1: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0604, Per-class F1: [0.9612 0.8916 1.     0.9892], Min F1: 0.8916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0377, Per-class F1: [0.9469 0.881  1.     0.989 ], Min F1: 0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0250, Per-class F1: [0.9859 0.961  1.     1.    ], Min F1: 0.9610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0495, Per-class F1: [0.9619 0.8974 0.9815 1.    ], Min F1: 0.8974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0838, Per-class F1: [0.9608 0.9176 0.9907 0.9783], Min F1: 0.9176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.57it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0458, Per-class F1: [0.9662 0.9268 0.9907 1.    ], Min F1: 0.9268\n",
      "\n",
      "===== Fold 4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5998, Per-class F1: [0.9709 0.975  0.9907 0.9474], Min F1: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.1798, Per-class F1: [0.9758 0.9873 0.9907 0.9474], Min F1: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.1105, Per-class F1: [0.9659 0.9512 0.9905 0.9583], Min F1: 0.9512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0880, Per-class F1: [0.9808 0.961  1.     0.9485], Min F1: 0.9485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0466, Per-class F1: [0.9756 0.9756 1.     0.9684], Min F1: 0.9684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0290, Per-class F1: [0.9904 1.     1.     0.9787], Min F1: 0.9787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0401, Per-class F1: [0.9904 0.9744 1.     0.9583], Min F1: 0.9583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0574, Per-class F1: [0.9758 0.963  0.9905 0.9684], Min F1: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0590, Per-class F1: [0.9565 0.9    0.9905 0.9583], Min F1: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.31it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0544, Per-class F1: [0.9662 0.8974 1.     0.9485], Min F1: 0.8974\n",
      "\n",
      "===== Fold 5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6375, Per-class F1: [0.9557 0.9136 0.9725 0.9263], Min F1: 0.9136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.1638, Per-class F1: [0.9806 0.9756 1.     0.9787], Min F1: 0.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.1098, Per-class F1: [0.9905 0.975  1.     1.    ], Min F1: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.1017, Per-class F1: [0.9952 0.9877 1.     1.    ], Min F1: 0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0723, Per-class F1: [0.9952 0.9877 1.     1.    ], Min F1: 0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0546, Per-class F1: [0.9763 0.9877 0.9907 0.9663], Min F1: 0.9663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0474, Per-class F1: [0.9904 0.9877 0.9907 1.    ], Min F1: 0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0777, Per-class F1: [1.     0.9873 1.     0.9892], Min F1: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0546, Per-class F1: [1.     0.9873 0.9907 1.    ], Min F1: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:07<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0497, Per-class F1: [0.9953 1.     1.     0.989 ], Min F1: 0.9890\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation training\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "models_list = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(labels_df, labels_df.label)):\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "    train_df = labels_df.iloc[train_idx]\n",
    "    val_df = labels_df.iloc[val_idx]\n",
    "\n",
    "    train_ds = SoilDataset(train_df, TRAIN_DIR, transform=train_transform)\n",
    "    val_ds = SoilDataset(val_df, TRAIN_DIR, transform=test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    model = create_model().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        f1s = validate(model, val_loader, device)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss:.4f}, Per-class F1: {np.round(f1s, 4)}, Min F1: {min(f1s):.4f}\")\n",
    "\n",
    "    models_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df2a6b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:16:28.445911Z",
     "iopub.status.busy": "2025-05-22T15:16:28.445564Z",
     "iopub.status.idle": "2025-05-22T15:18:22.390863Z",
     "shell.execute_reply": "2025-05-22T15:18:22.389733Z"
    },
    "papermill": {
     "duration": 114.026308,
     "end_time": "2025-05-22T15:18:22.392379",
     "exception": false,
     "start_time": "2025-05-22T15:16:28.366071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|██████████| 341/341 [01:53<00:00,  2.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Inference with Test-Time Augmentation (TTA) and model ensembling\n",
    "\n",
    "test_ids = pd.read_csv(TEST_IDS_PATH)  # Load the list of test image filenames\n",
    "\n",
    "# Custom Dataset class for test images (used in earlier training, here mainly for consistency)\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx][\"image_id\"]\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        return self.transform(image)\n",
    "\n",
    "# Define the TTA transform: random horizontal flips and small rotations to simulate different views\n",
    "tta_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to generate TTA predictions using a given model and image\n",
    "def tta_predict(model, image, n=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        for _ in range(n):\n",
    "            img = tta_transform(image)\n",
    "            img = img.unsqueeze(0).to(device)  \n",
    "            output = model(img)\n",
    "            preds.append(torch.softmax(output, dim=1).cpu().numpy())  # Get class probabilities\n",
    "        mean_pred = np.mean(preds, axis=0)  # Average predictions over n augmentations\n",
    "        return mean_pred.squeeze()  # Ensure shape is (num_classes,) not (1, num_classes)\n",
    "\n",
    "# Run inference with ensembling and TTA\n",
    "final_preds = []\n",
    "\n",
    "for i in tqdm(range(len(test_ids)), desc=\"Generating Predictions\"):\n",
    "    img_id = test_ids.iloc[i][\"image_id\"]\n",
    "    img_path = os.path.join(TEST_DIR, img_id)\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    pred_sum = np.zeros(len(class_names))  # Accumulate predictions across models\n",
    "    for model in models_list:\n",
    "        pred = tta_predict(model, image)  # Get TTA prediction for this model\n",
    "        pred_sum += pred  # Sum across ensemble models\n",
    "\n",
    "    final_label = pred_sum.argmax()  # Choose class with highest average probability\n",
    "    final_preds.append(idx_to_class[final_label])  # Convert index back to class name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ae4315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:18:22.584581Z",
     "iopub.status.busy": "2025-05-22T15:18:22.583790Z",
     "iopub.status.idle": "2025-05-22T15:18:22.588758Z",
     "shell.execute_reply": "2025-05-22T15:18:22.588040Z"
    },
    "papermill": {
     "duration": 0.103076,
     "end_time": "2025-05-22T15:18:22.590085",
     "exception": false,
     "start_time": "2025-05-22T15:18:22.487009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    \"image_id\": test_ids[\"image_id\"],\n",
    "    \"soil_type\": final_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b154d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T15:18:22.779256Z",
     "iopub.status.busy": "2025-05-22T15:18:22.778749Z",
     "iopub.status.idle": "2025-05-22T15:18:22.795543Z",
     "shell.execute_reply": "2025-05-22T15:18:22.794657Z"
    },
    "papermill": {
     "duration": 0.114349,
     "end_time": "2025-05-22T15:18:22.796919",
     "exception": false,
     "start_time": "2025-05-22T15:18:22.682570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Submission file saved to: submission.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save to CSV\n",
    "submission_path = \"submission.csv\"\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\" Submission file saved to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12375409,
     "sourceId": 102672,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 598.633586,
   "end_time": "2025-05-22T15:18:25.880858",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-22T15:08:27.247272",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
